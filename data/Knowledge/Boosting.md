Base models are trained sequentially, and then combined  through majority voting or averaging. In boosting, we perform  “weighted” resampling, so observations that were misclassified by the  previously trained base model have a greater chance of being sampled. 
A sequential [[Ensemble Methods]]. 
Reduces both bias and variance. 